{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11795580,"sourceType":"datasetVersion","datasetId":7407018}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers==4.40.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T10:36:11.184744Z","iopub.execute_input":"2025-05-23T10:36:11.184985Z","iopub.status.idle":"2025-05-23T10:36:24.781659Z","shell.execute_reply.started":"2025-05-23T10:36:11.184958Z","shell.execute_reply":"2025-05-23T10:36:24.780688Z"}},"outputs":[{"name":"stdout","text":"Collecting transformers==4.40.0\n  Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (2.32.3)\nCollecting tokenizers<0.20,>=0.19 (from transformers==4.40.0)\n  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.40.0) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.40.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.40.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.40.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.40.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.40.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.40.0) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.0) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.40.0) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.40.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.40.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.40.0) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.40.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.40.0) (2024.2.0)\nDownloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.1\n    Uninstalling tokenizers-0.21.1:\n      Successfully uninstalled tokenizers-0.21.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.3\n    Uninstalling transformers-4.51.3:\n      Successfully uninstalled transformers-4.51.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tokenizers-0.19.1 transformers-4.40.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoProcessor, AutoModelForCausalLM, AutoConfig\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndtype = torch.float16 if device==\"cuda\" else torch.float32\n\n# 1.1 Load config & processor\nconfig    = AutoConfig.from_pretrained(\"StanfordAIMI/CheXagent-8b\", trust_remote_code=True)\nprocessor = AutoProcessor.from_pretrained(\"StanfordAIMI/CheXagent-8b\", trust_remote_code=True)\n# 1.2 Load full model\nmodel     = AutoModelForCausalLM.from_pretrained(\n    \"StanfordAIMI/CheXagent-8b\",\n    config=config,\n    torch_dtype=dtype,\n    trust_remote_code=True,\n).to(device)\n\n# 1.3 Inspect sub-modules\nprint(model)                           # full vision-language model\nprint(model.vision_model)              # the vision encoder (a CLIPVision/QFormers stack)\nprint(model.qformer)                   # cross-modal Q-former\nprint(model.language_model)            # decoder LLM :contentReference[oaicite:0]{index=0}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T10:36:24.782787Z","iopub.execute_input":"2025-05-23T10:36:24.783076Z"}},"outputs":[{"name":"stderr","text":"2025-05-23 10:36:33.165942: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747996593.393140      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747996593.460253      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8927e2d153af4318a757c61b97d3a1af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_chexagent.py:   0%|          | 0.00/6.88k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13eac9296f37417f81d9888e105794f2"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/StanfordAIMI/CheXagent-8b:\n- configuration_chexagent.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/520 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70ba2e0424c54198b685c8c695b8d0f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"processing_chexagent.py:   0%|          | 0.00/5.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b19da32391474e9e94b94dcbb5ce0e46"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/StanfordAIMI/CheXagent-8b:\n- processing_chexagent.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/959 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49c80ba3832648a5965bd8a62aba0d79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b24edb6a590c4b1ab66e3c6e85631bb9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88dc448a3db94d8b89abbafcc05ca132"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86dbafc4db5b40b28939ef91a492ac68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modeling_chexagent.py:   0%|          | 0.00/55.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40fd4ae6ae66471a8790319156839728"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/StanfordAIMI/CheXagent-8b:\n- modeling_chexagent.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/98.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d0caa03f43b46b58b1a70411c96bfc2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ce942b1f41b476a870e00c159b971c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00007.safetensors:   0%|          | 0.00/4.48G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"171dc0715c7f4d7c92a128d3d90036b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00007.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a72785b989ff49c6a94b504b1642e1c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00007.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cfd798e9e304a60af375615cb7cfbfc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e85f91f2c6ac4129b0cc27035e912fef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bfde7334736417bbbb39a1dd8b8c961"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad26cd2f703243ef812b2e0062f7b0dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00007.safetensors:   0%|          | 0.00/4.25G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6323266ace0462780cabf3dd22df052"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a886ee0046324e08a22663b53aa93e55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b933fb4887444b9895214140097fc04"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# Simply grab the vision encoder submodule\nvision_encoder = model.vision_model\n# It already carries the learned chest-X-ray weights","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoConfig\n\nmodel_name = \"StanfordAIMI/CheXagent-8b\"\nconfig = AutoConfig.from_pretrained(model_name, trust_remote_code=True)\nprint(config)\n\n# You can specifically look at the vision model's configuration if it's structured that way\nif hasattr(config, 'vision_config'):\n    print(\"\\nVision Encoder Configuration:\")\n    print(config.vision_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T12:24:15.325629Z","iopub.execute_input":"2025-05-22T12:24:15.325849Z","iopub.status.idle":"2025-05-22T12:24:27.411438Z","shell.execute_reply.started":"2025-05-22T12:24:15.325824Z","shell.execute_reply":"2025-05-22T12:24:27.410758Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a08e27fc19ac483ab47b636f6cb3fffb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_chexagent.py:   0%|          | 0.00/6.88k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a3225ada27a4a7e9e21a589153570b4"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/StanfordAIMI/CheXagent-8b:\n- configuration_chexagent.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"name":"stdout","text":"CheXagentConfig {\n  \"architectures\": [\n    \"CheXagentForConditionalGeneration\"\n  ],\n  \"auto_map\": {\n    \"AutoConfig\": \"StanfordAIMI/CheXagent-8b--configuration_chexagent.CheXagentConfig\",\n    \"AutoModelForCausalLM\": \"StanfordAIMI/CheXagent-8b--modeling_chexagent.CheXagentForConditionalGeneration\"\n  },\n  \"initializer_factor\": 1.0,\n  \"initializer_range\": 0.02,\n  \"model_type\": \"chexagent\",\n  \"num_max_images\": 2,\n  \"num_query_tokens\": 128,\n  \"qformer_config\": {\n    \"attention_probs_dropout_prob\": 0.1,\n    \"cross_attention_frequency\": 2,\n    \"encoder_hidden_size\": 1408,\n    \"hidden_act\": \"gelu\",\n    \"hidden_dropout_prob\": 0.1,\n    \"hidden_size\": 768,\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 3072,\n    \"layer_norm_eps\": 1e-12,\n    \"max_position_embeddings\": 512,\n    \"model_type\": \"chexagent_qformer\",\n    \"num_attention_heads\": 12,\n    \"num_hidden_layers\": 12,\n    \"position_embedding_type\": \"absolute\",\n    \"vocab_size\": 30523\n  },\n  \"text_config\": {\n    \"_name_or_path\": \"mistralai/Mistral-7B-v0.1\",\n    \"architectures\": [\n      \"MistralForCausalLM\"\n    ],\n    \"attention_bias\": false,\n    \"attention_dropout\": 0.0,\n    \"head_dim\": 128,\n    \"hidden_act\": \"silu\",\n    \"hidden_size\": 4096,\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 14336,\n    \"max_position_embeddings\": 32768,\n    \"model_type\": \"mistral\",\n    \"num_attention_heads\": 32,\n    \"num_hidden_layers\": 32,\n    \"num_key_value_heads\": 8,\n    \"pretraining_tp\": 1,\n    \"rms_norm_eps\": 1e-05,\n    \"rope_scaling\": null,\n    \"rope_theta\": 10000.0,\n    \"sliding_window\": 4096,\n    \"torch_dtype\": \"bfloat16\",\n    \"use_cache\": true,\n    \"vocab_size\": 32000\n  },\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.51.3\",\n  \"use_decoder_only_language_model\": true,\n  \"vision_config\": {\n    \"attention_dropout\": 0.0,\n    \"hidden_act\": \"gelu\",\n    \"hidden_size\": 1408,\n    \"image_size\": 448,\n    \"initializer_range\": 1e-10,\n    \"intermediate_size\": 6144,\n    \"layer_norm_eps\": 1e-06,\n    \"model_type\": \"chexagent_vision_model\",\n    \"num_attention_heads\": 16,\n    \"num_hidden_layers\": 40,\n    \"patch_size\": 14,\n    \"qkv_bias\": true\n  }\n}\n\n\nVision Encoder Configuration:\nCheXagentVisionConfig {\n  \"attention_dropout\": 0.0,\n  \"hidden_act\": \"gelu\",\n  \"hidden_size\": 1408,\n  \"image_size\": 448,\n  \"initializer_range\": 1e-10,\n  \"intermediate_size\": 6144,\n  \"layer_norm_eps\": 1e-06,\n  \"model_type\": \"chexagent_vision_model\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 40,\n  \"patch_size\": 14,\n  \"qkv_bias\": true,\n  \"transformers_version\": \"4.51.3\"\n}\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoProcessor, AutoModelForCausalLM, GenerationConfig\nimport torch\n\ndevice = \"cuda\"\ndtype = torch.float16\n\n# 1. Load processor + model (this will pull in the custom CheXagent code)\nprocessor = AutoProcessor.from_pretrained(\"StanfordAIMI/CheXagent-8b\", trust_remote_code=True)\ngen_config = GenerationConfig.from_pretrained(\"StanfordAIMI/CheXagent-8b\")\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"StanfordAIMI/CheXagent-8b\",\n    torch_dtype=dtype,\n    trust_remote_code=True\n)\n\n# 2. Inspect its submodules to find the vision encoder\nprint([n for n, _ in model.named_modules() if \"vision\" in n.lower()])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T13:19:58.323813Z","iopub.execute_input":"2025-05-22T13:19:58.324076Z","iopub.status.idle":"2025-05-22T13:23:14.218015Z","shell.execute_reply.started":"2025-05-22T13:19:58.324053Z","shell.execute_reply":"2025-05-22T13:23:14.217194Z"}},"outputs":[{"name":"stderr","text":"2025-05-22 13:20:09.792454: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747920009.993014      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747920010.055188      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/520 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2af4267a0e4b43ed957d4efa16cc3dd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"processing_chexagent.py:   0%|          | 0.00/5.28k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70ba134b4eec4b22917c0eef27931989"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/StanfordAIMI/CheXagent-8b:\n- processing_chexagent.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/959 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eb9faa6478c46779f65451a535c8661"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bed426e644234f6884c4272d7395cfc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba43b8fe2d214cb9b8e5ba92792bdb10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9db4effeae82471d8a4ed7a0e5c1732f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/280 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60532104f71c410d80d65d243c591cf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90b9e7079b2f4f499ac341815ed899ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_chexagent.py:   0%|          | 0.00/6.88k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bb73a66290a498f90f76baf1fb748d2"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/StanfordAIMI/CheXagent-8b:\n- configuration_chexagent.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_chexagent.py:   0%|          | 0.00/55.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"178c508ce16c45c89535b25c9a50c8af"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/StanfordAIMI/CheXagent-8b:\n- modeling_chexagent.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/98.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18187e1a59fe4bebb4f3f6e082c23cb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d400cb14a67641179a41a6a83d549836"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00007.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f875224daa9a49cd8f01d62937b552e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00007.safetensors:   0%|          | 0.00/4.48G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0536e79b5e64dddbe9abbc51ebc29cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"242cf6a874d94758aed745762a78d725"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00007.safetensors:   0%|          | 0.00/4.83G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10752ec252a94979be2a2b2856d19c6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00007.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cdadbeb980645b18ae5ac17d4fcc088"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00007.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"295a49fbfb924742b98d8d43d603d958"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00007.safetensors:   0%|          | 0.00/4.25G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e687c1efcbc44f96bbf334c5366de7c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dec0abc317fc492da8ca592a01465386"}},"metadata":{}},{"name":"stdout","text":"['vision_model', 'vision_model.embeddings', 'vision_model.embeddings.patch_embedding', 'vision_model.encoder', 'vision_model.encoder.layers', 'vision_model.encoder.layers.0', 'vision_model.encoder.layers.0.self_attn', 'vision_model.encoder.layers.0.self_attn.dropout', 'vision_model.encoder.layers.0.self_attn.qkv', 'vision_model.encoder.layers.0.self_attn.projection', 'vision_model.encoder.layers.0.layer_norm1', 'vision_model.encoder.layers.0.mlp', 'vision_model.encoder.layers.0.mlp.activation_fn', 'vision_model.encoder.layers.0.mlp.fc1', 'vision_model.encoder.layers.0.mlp.fc2', 'vision_model.encoder.layers.0.layer_norm2', 'vision_model.encoder.layers.1', 'vision_model.encoder.layers.1.self_attn', 'vision_model.encoder.layers.1.self_attn.dropout', 'vision_model.encoder.layers.1.self_attn.qkv', 'vision_model.encoder.layers.1.self_attn.projection', 'vision_model.encoder.layers.1.layer_norm1', 'vision_model.encoder.layers.1.mlp', 'vision_model.encoder.layers.1.mlp.activation_fn', 'vision_model.encoder.layers.1.mlp.fc1', 'vision_model.encoder.layers.1.mlp.fc2', 'vision_model.encoder.layers.1.layer_norm2', 'vision_model.encoder.layers.2', 'vision_model.encoder.layers.2.self_attn', 'vision_model.encoder.layers.2.self_attn.dropout', 'vision_model.encoder.layers.2.self_attn.qkv', 'vision_model.encoder.layers.2.self_attn.projection', 'vision_model.encoder.layers.2.layer_norm1', 'vision_model.encoder.layers.2.mlp', 'vision_model.encoder.layers.2.mlp.activation_fn', 'vision_model.encoder.layers.2.mlp.fc1', 'vision_model.encoder.layers.2.mlp.fc2', 'vision_model.encoder.layers.2.layer_norm2', 'vision_model.encoder.layers.3', 'vision_model.encoder.layers.3.self_attn', 'vision_model.encoder.layers.3.self_attn.dropout', 'vision_model.encoder.layers.3.self_attn.qkv', 'vision_model.encoder.layers.3.self_attn.projection', 'vision_model.encoder.layers.3.layer_norm1', 'vision_model.encoder.layers.3.mlp', 'vision_model.encoder.layers.3.mlp.activation_fn', 'vision_model.encoder.layers.3.mlp.fc1', 'vision_model.encoder.layers.3.mlp.fc2', 'vision_model.encoder.layers.3.layer_norm2', 'vision_model.encoder.layers.4', 'vision_model.encoder.layers.4.self_attn', 'vision_model.encoder.layers.4.self_attn.dropout', 'vision_model.encoder.layers.4.self_attn.qkv', 'vision_model.encoder.layers.4.self_attn.projection', 'vision_model.encoder.layers.4.layer_norm1', 'vision_model.encoder.layers.4.mlp', 'vision_model.encoder.layers.4.mlp.activation_fn', 'vision_model.encoder.layers.4.mlp.fc1', 'vision_model.encoder.layers.4.mlp.fc2', 'vision_model.encoder.layers.4.layer_norm2', 'vision_model.encoder.layers.5', 'vision_model.encoder.layers.5.self_attn', 'vision_model.encoder.layers.5.self_attn.dropout', 'vision_model.encoder.layers.5.self_attn.qkv', 'vision_model.encoder.layers.5.self_attn.projection', 'vision_model.encoder.layers.5.layer_norm1', 'vision_model.encoder.layers.5.mlp', 'vision_model.encoder.layers.5.mlp.activation_fn', 'vision_model.encoder.layers.5.mlp.fc1', 'vision_model.encoder.layers.5.mlp.fc2', 'vision_model.encoder.layers.5.layer_norm2', 'vision_model.encoder.layers.6', 'vision_model.encoder.layers.6.self_attn', 'vision_model.encoder.layers.6.self_attn.dropout', 'vision_model.encoder.layers.6.self_attn.qkv', 'vision_model.encoder.layers.6.self_attn.projection', 'vision_model.encoder.layers.6.layer_norm1', 'vision_model.encoder.layers.6.mlp', 'vision_model.encoder.layers.6.mlp.activation_fn', 'vision_model.encoder.layers.6.mlp.fc1', 'vision_model.encoder.layers.6.mlp.fc2', 'vision_model.encoder.layers.6.layer_norm2', 'vision_model.encoder.layers.7', 'vision_model.encoder.layers.7.self_attn', 'vision_model.encoder.layers.7.self_attn.dropout', 'vision_model.encoder.layers.7.self_attn.qkv', 'vision_model.encoder.layers.7.self_attn.projection', 'vision_model.encoder.layers.7.layer_norm1', 'vision_model.encoder.layers.7.mlp', 'vision_model.encoder.layers.7.mlp.activation_fn', 'vision_model.encoder.layers.7.mlp.fc1', 'vision_model.encoder.layers.7.mlp.fc2', 'vision_model.encoder.layers.7.layer_norm2', 'vision_model.encoder.layers.8', 'vision_model.encoder.layers.8.self_attn', 'vision_model.encoder.layers.8.self_attn.dropout', 'vision_model.encoder.layers.8.self_attn.qkv', 'vision_model.encoder.layers.8.self_attn.projection', 'vision_model.encoder.layers.8.layer_norm1', 'vision_model.encoder.layers.8.mlp', 'vision_model.encoder.layers.8.mlp.activation_fn', 'vision_model.encoder.layers.8.mlp.fc1', 'vision_model.encoder.layers.8.mlp.fc2', 'vision_model.encoder.layers.8.layer_norm2', 'vision_model.encoder.layers.9', 'vision_model.encoder.layers.9.self_attn', 'vision_model.encoder.layers.9.self_attn.dropout', 'vision_model.encoder.layers.9.self_attn.qkv', 'vision_model.encoder.layers.9.self_attn.projection', 'vision_model.encoder.layers.9.layer_norm1', 'vision_model.encoder.layers.9.mlp', 'vision_model.encoder.layers.9.mlp.activation_fn', 'vision_model.encoder.layers.9.mlp.fc1', 'vision_model.encoder.layers.9.mlp.fc2', 'vision_model.encoder.layers.9.layer_norm2', 'vision_model.encoder.layers.10', 'vision_model.encoder.layers.10.self_attn', 'vision_model.encoder.layers.10.self_attn.dropout', 'vision_model.encoder.layers.10.self_attn.qkv', 'vision_model.encoder.layers.10.self_attn.projection', 'vision_model.encoder.layers.10.layer_norm1', 'vision_model.encoder.layers.10.mlp', 'vision_model.encoder.layers.10.mlp.activation_fn', 'vision_model.encoder.layers.10.mlp.fc1', 'vision_model.encoder.layers.10.mlp.fc2', 'vision_model.encoder.layers.10.layer_norm2', 'vision_model.encoder.layers.11', 'vision_model.encoder.layers.11.self_attn', 'vision_model.encoder.layers.11.self_attn.dropout', 'vision_model.encoder.layers.11.self_attn.qkv', 'vision_model.encoder.layers.11.self_attn.projection', 'vision_model.encoder.layers.11.layer_norm1', 'vision_model.encoder.layers.11.mlp', 'vision_model.encoder.layers.11.mlp.activation_fn', 'vision_model.encoder.layers.11.mlp.fc1', 'vision_model.encoder.layers.11.mlp.fc2', 'vision_model.encoder.layers.11.layer_norm2', 'vision_model.encoder.layers.12', 'vision_model.encoder.layers.12.self_attn', 'vision_model.encoder.layers.12.self_attn.dropout', 'vision_model.encoder.layers.12.self_attn.qkv', 'vision_model.encoder.layers.12.self_attn.projection', 'vision_model.encoder.layers.12.layer_norm1', 'vision_model.encoder.layers.12.mlp', 'vision_model.encoder.layers.12.mlp.activation_fn', 'vision_model.encoder.layers.12.mlp.fc1', 'vision_model.encoder.layers.12.mlp.fc2', 'vision_model.encoder.layers.12.layer_norm2', 'vision_model.encoder.layers.13', 'vision_model.encoder.layers.13.self_attn', 'vision_model.encoder.layers.13.self_attn.dropout', 'vision_model.encoder.layers.13.self_attn.qkv', 'vision_model.encoder.layers.13.self_attn.projection', 'vision_model.encoder.layers.13.layer_norm1', 'vision_model.encoder.layers.13.mlp', 'vision_model.encoder.layers.13.mlp.activation_fn', 'vision_model.encoder.layers.13.mlp.fc1', 'vision_model.encoder.layers.13.mlp.fc2', 'vision_model.encoder.layers.13.layer_norm2', 'vision_model.encoder.layers.14', 'vision_model.encoder.layers.14.self_attn', 'vision_model.encoder.layers.14.self_attn.dropout', 'vision_model.encoder.layers.14.self_attn.qkv', 'vision_model.encoder.layers.14.self_attn.projection', 'vision_model.encoder.layers.14.layer_norm1', 'vision_model.encoder.layers.14.mlp', 'vision_model.encoder.layers.14.mlp.activation_fn', 'vision_model.encoder.layers.14.mlp.fc1', 'vision_model.encoder.layers.14.mlp.fc2', 'vision_model.encoder.layers.14.layer_norm2', 'vision_model.encoder.layers.15', 'vision_model.encoder.layers.15.self_attn', 'vision_model.encoder.layers.15.self_attn.dropout', 'vision_model.encoder.layers.15.self_attn.qkv', 'vision_model.encoder.layers.15.self_attn.projection', 'vision_model.encoder.layers.15.layer_norm1', 'vision_model.encoder.layers.15.mlp', 'vision_model.encoder.layers.15.mlp.activation_fn', 'vision_model.encoder.layers.15.mlp.fc1', 'vision_model.encoder.layers.15.mlp.fc2', 'vision_model.encoder.layers.15.layer_norm2', 'vision_model.encoder.layers.16', 'vision_model.encoder.layers.16.self_attn', 'vision_model.encoder.layers.16.self_attn.dropout', 'vision_model.encoder.layers.16.self_attn.qkv', 'vision_model.encoder.layers.16.self_attn.projection', 'vision_model.encoder.layers.16.layer_norm1', 'vision_model.encoder.layers.16.mlp', 'vision_model.encoder.layers.16.mlp.activation_fn', 'vision_model.encoder.layers.16.mlp.fc1', 'vision_model.encoder.layers.16.mlp.fc2', 'vision_model.encoder.layers.16.layer_norm2', 'vision_model.encoder.layers.17', 'vision_model.encoder.layers.17.self_attn', 'vision_model.encoder.layers.17.self_attn.dropout', 'vision_model.encoder.layers.17.self_attn.qkv', 'vision_model.encoder.layers.17.self_attn.projection', 'vision_model.encoder.layers.17.layer_norm1', 'vision_model.encoder.layers.17.mlp', 'vision_model.encoder.layers.17.mlp.activation_fn', 'vision_model.encoder.layers.17.mlp.fc1', 'vision_model.encoder.layers.17.mlp.fc2', 'vision_model.encoder.layers.17.layer_norm2', 'vision_model.encoder.layers.18', 'vision_model.encoder.layers.18.self_attn', 'vision_model.encoder.layers.18.self_attn.dropout', 'vision_model.encoder.layers.18.self_attn.qkv', 'vision_model.encoder.layers.18.self_attn.projection', 'vision_model.encoder.layers.18.layer_norm1', 'vision_model.encoder.layers.18.mlp', 'vision_model.encoder.layers.18.mlp.activation_fn', 'vision_model.encoder.layers.18.mlp.fc1', 'vision_model.encoder.layers.18.mlp.fc2', 'vision_model.encoder.layers.18.layer_norm2', 'vision_model.encoder.layers.19', 'vision_model.encoder.layers.19.self_attn', 'vision_model.encoder.layers.19.self_attn.dropout', 'vision_model.encoder.layers.19.self_attn.qkv', 'vision_model.encoder.layers.19.self_attn.projection', 'vision_model.encoder.layers.19.layer_norm1', 'vision_model.encoder.layers.19.mlp', 'vision_model.encoder.layers.19.mlp.activation_fn', 'vision_model.encoder.layers.19.mlp.fc1', 'vision_model.encoder.layers.19.mlp.fc2', 'vision_model.encoder.layers.19.layer_norm2', 'vision_model.encoder.layers.20', 'vision_model.encoder.layers.20.self_attn', 'vision_model.encoder.layers.20.self_attn.dropout', 'vision_model.encoder.layers.20.self_attn.qkv', 'vision_model.encoder.layers.20.self_attn.projection', 'vision_model.encoder.layers.20.layer_norm1', 'vision_model.encoder.layers.20.mlp', 'vision_model.encoder.layers.20.mlp.activation_fn', 'vision_model.encoder.layers.20.mlp.fc1', 'vision_model.encoder.layers.20.mlp.fc2', 'vision_model.encoder.layers.20.layer_norm2', 'vision_model.encoder.layers.21', 'vision_model.encoder.layers.21.self_attn', 'vision_model.encoder.layers.21.self_attn.dropout', 'vision_model.encoder.layers.21.self_attn.qkv', 'vision_model.encoder.layers.21.self_attn.projection', 'vision_model.encoder.layers.21.layer_norm1', 'vision_model.encoder.layers.21.mlp', 'vision_model.encoder.layers.21.mlp.activation_fn', 'vision_model.encoder.layers.21.mlp.fc1', 'vision_model.encoder.layers.21.mlp.fc2', 'vision_model.encoder.layers.21.layer_norm2', 'vision_model.encoder.layers.22', 'vision_model.encoder.layers.22.self_attn', 'vision_model.encoder.layers.22.self_attn.dropout', 'vision_model.encoder.layers.22.self_attn.qkv', 'vision_model.encoder.layers.22.self_attn.projection', 'vision_model.encoder.layers.22.layer_norm1', 'vision_model.encoder.layers.22.mlp', 'vision_model.encoder.layers.22.mlp.activation_fn', 'vision_model.encoder.layers.22.mlp.fc1', 'vision_model.encoder.layers.22.mlp.fc2', 'vision_model.encoder.layers.22.layer_norm2', 'vision_model.encoder.layers.23', 'vision_model.encoder.layers.23.self_attn', 'vision_model.encoder.layers.23.self_attn.dropout', 'vision_model.encoder.layers.23.self_attn.qkv', 'vision_model.encoder.layers.23.self_attn.projection', 'vision_model.encoder.layers.23.layer_norm1', 'vision_model.encoder.layers.23.mlp', 'vision_model.encoder.layers.23.mlp.activation_fn', 'vision_model.encoder.layers.23.mlp.fc1', 'vision_model.encoder.layers.23.mlp.fc2', 'vision_model.encoder.layers.23.layer_norm2', 'vision_model.encoder.layers.24', 'vision_model.encoder.layers.24.self_attn', 'vision_model.encoder.layers.24.self_attn.dropout', 'vision_model.encoder.layers.24.self_attn.qkv', 'vision_model.encoder.layers.24.self_attn.projection', 'vision_model.encoder.layers.24.layer_norm1', 'vision_model.encoder.layers.24.mlp', 'vision_model.encoder.layers.24.mlp.activation_fn', 'vision_model.encoder.layers.24.mlp.fc1', 'vision_model.encoder.layers.24.mlp.fc2', 'vision_model.encoder.layers.24.layer_norm2', 'vision_model.encoder.layers.25', 'vision_model.encoder.layers.25.self_attn', 'vision_model.encoder.layers.25.self_attn.dropout', 'vision_model.encoder.layers.25.self_attn.qkv', 'vision_model.encoder.layers.25.self_attn.projection', 'vision_model.encoder.layers.25.layer_norm1', 'vision_model.encoder.layers.25.mlp', 'vision_model.encoder.layers.25.mlp.activation_fn', 'vision_model.encoder.layers.25.mlp.fc1', 'vision_model.encoder.layers.25.mlp.fc2', 'vision_model.encoder.layers.25.layer_norm2', 'vision_model.encoder.layers.26', 'vision_model.encoder.layers.26.self_attn', 'vision_model.encoder.layers.26.self_attn.dropout', 'vision_model.encoder.layers.26.self_attn.qkv', 'vision_model.encoder.layers.26.self_attn.projection', 'vision_model.encoder.layers.26.layer_norm1', 'vision_model.encoder.layers.26.mlp', 'vision_model.encoder.layers.26.mlp.activation_fn', 'vision_model.encoder.layers.26.mlp.fc1', 'vision_model.encoder.layers.26.mlp.fc2', 'vision_model.encoder.layers.26.layer_norm2', 'vision_model.encoder.layers.27', 'vision_model.encoder.layers.27.self_attn', 'vision_model.encoder.layers.27.self_attn.dropout', 'vision_model.encoder.layers.27.self_attn.qkv', 'vision_model.encoder.layers.27.self_attn.projection', 'vision_model.encoder.layers.27.layer_norm1', 'vision_model.encoder.layers.27.mlp', 'vision_model.encoder.layers.27.mlp.activation_fn', 'vision_model.encoder.layers.27.mlp.fc1', 'vision_model.encoder.layers.27.mlp.fc2', 'vision_model.encoder.layers.27.layer_norm2', 'vision_model.encoder.layers.28', 'vision_model.encoder.layers.28.self_attn', 'vision_model.encoder.layers.28.self_attn.dropout', 'vision_model.encoder.layers.28.self_attn.qkv', 'vision_model.encoder.layers.28.self_attn.projection', 'vision_model.encoder.layers.28.layer_norm1', 'vision_model.encoder.layers.28.mlp', 'vision_model.encoder.layers.28.mlp.activation_fn', 'vision_model.encoder.layers.28.mlp.fc1', 'vision_model.encoder.layers.28.mlp.fc2', 'vision_model.encoder.layers.28.layer_norm2', 'vision_model.encoder.layers.29', 'vision_model.encoder.layers.29.self_attn', 'vision_model.encoder.layers.29.self_attn.dropout', 'vision_model.encoder.layers.29.self_attn.qkv', 'vision_model.encoder.layers.29.self_attn.projection', 'vision_model.encoder.layers.29.layer_norm1', 'vision_model.encoder.layers.29.mlp', 'vision_model.encoder.layers.29.mlp.activation_fn', 'vision_model.encoder.layers.29.mlp.fc1', 'vision_model.encoder.layers.29.mlp.fc2', 'vision_model.encoder.layers.29.layer_norm2', 'vision_model.encoder.layers.30', 'vision_model.encoder.layers.30.self_attn', 'vision_model.encoder.layers.30.self_attn.dropout', 'vision_model.encoder.layers.30.self_attn.qkv', 'vision_model.encoder.layers.30.self_attn.projection', 'vision_model.encoder.layers.30.layer_norm1', 'vision_model.encoder.layers.30.mlp', 'vision_model.encoder.layers.30.mlp.activation_fn', 'vision_model.encoder.layers.30.mlp.fc1', 'vision_model.encoder.layers.30.mlp.fc2', 'vision_model.encoder.layers.30.layer_norm2', 'vision_model.encoder.layers.31', 'vision_model.encoder.layers.31.self_attn', 'vision_model.encoder.layers.31.self_attn.dropout', 'vision_model.encoder.layers.31.self_attn.qkv', 'vision_model.encoder.layers.31.self_attn.projection', 'vision_model.encoder.layers.31.layer_norm1', 'vision_model.encoder.layers.31.mlp', 'vision_model.encoder.layers.31.mlp.activation_fn', 'vision_model.encoder.layers.31.mlp.fc1', 'vision_model.encoder.layers.31.mlp.fc2', 'vision_model.encoder.layers.31.layer_norm2', 'vision_model.encoder.layers.32', 'vision_model.encoder.layers.32.self_attn', 'vision_model.encoder.layers.32.self_attn.dropout', 'vision_model.encoder.layers.32.self_attn.qkv', 'vision_model.encoder.layers.32.self_attn.projection', 'vision_model.encoder.layers.32.layer_norm1', 'vision_model.encoder.layers.32.mlp', 'vision_model.encoder.layers.32.mlp.activation_fn', 'vision_model.encoder.layers.32.mlp.fc1', 'vision_model.encoder.layers.32.mlp.fc2', 'vision_model.encoder.layers.32.layer_norm2', 'vision_model.encoder.layers.33', 'vision_model.encoder.layers.33.self_attn', 'vision_model.encoder.layers.33.self_attn.dropout', 'vision_model.encoder.layers.33.self_attn.qkv', 'vision_model.encoder.layers.33.self_attn.projection', 'vision_model.encoder.layers.33.layer_norm1', 'vision_model.encoder.layers.33.mlp', 'vision_model.encoder.layers.33.mlp.activation_fn', 'vision_model.encoder.layers.33.mlp.fc1', 'vision_model.encoder.layers.33.mlp.fc2', 'vision_model.encoder.layers.33.layer_norm2', 'vision_model.encoder.layers.34', 'vision_model.encoder.layers.34.self_attn', 'vision_model.encoder.layers.34.self_attn.dropout', 'vision_model.encoder.layers.34.self_attn.qkv', 'vision_model.encoder.layers.34.self_attn.projection', 'vision_model.encoder.layers.34.layer_norm1', 'vision_model.encoder.layers.34.mlp', 'vision_model.encoder.layers.34.mlp.activation_fn', 'vision_model.encoder.layers.34.mlp.fc1', 'vision_model.encoder.layers.34.mlp.fc2', 'vision_model.encoder.layers.34.layer_norm2', 'vision_model.encoder.layers.35', 'vision_model.encoder.layers.35.self_attn', 'vision_model.encoder.layers.35.self_attn.dropout', 'vision_model.encoder.layers.35.self_attn.qkv', 'vision_model.encoder.layers.35.self_attn.projection', 'vision_model.encoder.layers.35.layer_norm1', 'vision_model.encoder.layers.35.mlp', 'vision_model.encoder.layers.35.mlp.activation_fn', 'vision_model.encoder.layers.35.mlp.fc1', 'vision_model.encoder.layers.35.mlp.fc2', 'vision_model.encoder.layers.35.layer_norm2', 'vision_model.encoder.layers.36', 'vision_model.encoder.layers.36.self_attn', 'vision_model.encoder.layers.36.self_attn.dropout', 'vision_model.encoder.layers.36.self_attn.qkv', 'vision_model.encoder.layers.36.self_attn.projection', 'vision_model.encoder.layers.36.layer_norm1', 'vision_model.encoder.layers.36.mlp', 'vision_model.encoder.layers.36.mlp.activation_fn', 'vision_model.encoder.layers.36.mlp.fc1', 'vision_model.encoder.layers.36.mlp.fc2', 'vision_model.encoder.layers.36.layer_norm2', 'vision_model.encoder.layers.37', 'vision_model.encoder.layers.37.self_attn', 'vision_model.encoder.layers.37.self_attn.dropout', 'vision_model.encoder.layers.37.self_attn.qkv', 'vision_model.encoder.layers.37.self_attn.projection', 'vision_model.encoder.layers.37.layer_norm1', 'vision_model.encoder.layers.37.mlp', 'vision_model.encoder.layers.37.mlp.activation_fn', 'vision_model.encoder.layers.37.mlp.fc1', 'vision_model.encoder.layers.37.mlp.fc2', 'vision_model.encoder.layers.37.layer_norm2', 'vision_model.encoder.layers.38', 'vision_model.encoder.layers.38.self_attn', 'vision_model.encoder.layers.38.self_attn.dropout', 'vision_model.encoder.layers.38.self_attn.qkv', 'vision_model.encoder.layers.38.self_attn.projection', 'vision_model.encoder.layers.38.layer_norm1', 'vision_model.encoder.layers.38.mlp', 'vision_model.encoder.layers.38.mlp.activation_fn', 'vision_model.encoder.layers.38.mlp.fc1', 'vision_model.encoder.layers.38.mlp.fc2', 'vision_model.encoder.layers.38.layer_norm2', 'vision_model.encoder.layers.39', 'vision_model.encoder.layers.39.self_attn', 'vision_model.encoder.layers.39.self_attn.dropout', 'vision_model.encoder.layers.39.self_attn.qkv', 'vision_model.encoder.layers.39.self_attn.projection', 'vision_model.encoder.layers.39.layer_norm1', 'vision_model.encoder.layers.39.mlp', 'vision_model.encoder.layers.39.mlp.activation_fn', 'vision_model.encoder.layers.39.mlp.fc1', 'vision_model.encoder.layers.39.mlp.fc2', 'vision_model.encoder.layers.39.layer_norm2', 'vision_model.post_layernorm']\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# assuming the encoder is at model.vision_model\nvision_encoder = model.vision_model\n# freeze if you like\nfor p in vision_encoder.parameters():\n    p.requires_grad = False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T13:23:32.785623Z","iopub.execute_input":"2025-05-22T13:23:32.785893Z","iopub.status.idle":"2025-05-22T13:23:32.790892Z","shell.execute_reply.started":"2025-05-22T13:23:32.785875Z","shell.execute_reply":"2025-05-22T13:23:32.790289Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig\nimport torch\n\n# 1. load processor & full agent\nprocessor = AutoProcessor.from_pretrained(\"StanfordAIMI/CheXagent-8b\", trust_remote_code=True)\ngeneration_config = GenerationConfig.from_pretrained(\"StanfordAIMI/CheXagent-8b\")\nagent = AutoModelForCausalLM.from_pretrained(\n    \"StanfordAIMI/CheXagent-8b\",\n    torch_dtype=torch.float16,\n    trust_remote_code=True,\n)\n\n# 2. inspect vision sub-module\nvision_encoder = agent.vision_model\nprint(vision_encoder)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T13:25:32.246146Z","iopub.execute_input":"2025-05-22T13:25:32.246422Z","iopub.status.idle":"2025-05-22T13:25:36.479729Z","shell.execute_reply.started":"2025-05-22T13:25:32.246405Z","shell.execute_reply":"2025-05-22T13:25:36.479092Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4dfc3abbb974f4299a8032e0b21fced"}},"metadata":{}},{"name":"stdout","text":"CheXagentVisionModel(\n  (embeddings): CheXagentVisionEmbeddings(\n    (patch_embedding): Conv2d(3, 1408, kernel_size=(14, 14), stride=(14, 14))\n  )\n  (encoder): CheXagentEncoder(\n    (layers): ModuleList(\n      (0-39): 40 x CheXagentEncoderLayer(\n        (self_attn): CheXagentAttention(\n          (dropout): Dropout(p=0.0, inplace=False)\n          (qkv): Linear(in_features=1408, out_features=4224, bias=True)\n          (projection): Linear(in_features=1408, out_features=1408, bias=True)\n        )\n        (layer_norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n        (mlp): CheXagentMLP(\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n          (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n        )\n        (layer_norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n      )\n    )\n  )\n  (post_layernorm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}